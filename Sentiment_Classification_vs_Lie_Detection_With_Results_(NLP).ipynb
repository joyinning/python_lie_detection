{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyP9Yth8BiuVFuSKIpVM1a06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joyinning/python_lie_detection/blob/main/Sentiment_Classification_vs_Lie_Detection_With_Results_(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Information**"
      ],
      "metadata": {
        "id": "z8hD7riXRfZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Background** <br>\n",
        "There are many machine learning solutions to detect if a person is lying or not. "
      ],
      "metadata": {
        "id": "fCSJwW6YSQF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is **Sentiment Classification**?\n",
        "- It analyzes the sentiment or emotional tone using text data, such as a review, and determines whether it is positive, negative, or neutral. \n",
        "- It is used for understanding the overall sentiment expressed in the text. \n",
        "\n",
        "What is **Lie Detection**?\n",
        "- It involves identifying whether a statement is true or false. \n",
        "- It is used for detecting whether the texts are accuract or not, analyzing the factual things made in the text."
      ],
      "metadata": {
        "id": "-owPeSigS0Dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Goal** <br>\n",
        "The goal of this research is as follows.\n",
        "- To build sentiment classification and lie detection using the reviews of hotels in the United States.\n",
        "- To understand the difference between sentiment classification and lie detection and conclude which model can make a better performance.\n",
        "> While sentiment classification and lie detection both analyze text data, they are fundamentally using different features. \n",
        "> > In other words, Sentiment classification focuses on emotions and opinions, while lie detection focuses on the accuracy of factual claims. \n",
        "- To calculate gain ratio scores and select the top features."
      ],
      "metadata": {
        "id": "rEacXT62Rhhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Research Process** <br>\n",
        "The research will be conducted as the following process.\n",
        "\n",
        "1. **Data Preprocessing** <br>\n",
        "Upload, clean, (transform, if needed), and explore the data set to decide which values we should use to build an algorithm.\n",
        "\n",
        "2. **Text Preprocessing** <br>\n",
        "Clean and preprocess the review data by tokenizing, removing stop words and punctuations, converting to lowercase, lemmitizing, and stemming for setting the reviews for the required form of models of NLP. \n",
        "\n",
        "3. **Vectorization and Feature Selection** <br>\n",
        "Vectorize the preprocessed text data and select the top 15 features using gain ratio scores.\n",
        "\n",
        "4. **Building the Sentiment Classification and Lie Detection Model** <br>\n",
        "Split the dataset into training and testing sets, train a machine learning algorithm such as MultinomialNB, SVM, Decision Tree, and Random Forest, evaluate the models, and conduct hyperparameter tuning for improvements, if needed. \n",
        "\n",
        "5. **Evaluating the Models** <br>\n",
        "Compare the results of each algorithm and think about the nest step for improvements of those models. "
      ],
      "metadata": {
        "id": "etOkJXKsUDVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Data Preprocessing**"
      ],
      "metadata": {
        "id": "n4ACmRAakOHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is for preparing and exploring the given data set (the reviews of US hotels) for further machine learning research. "
      ],
      "metadata": {
        "id": "oC_Fqy8kSgBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) Upload the data set**"
      ],
      "metadata": {
        "id": "J_L2TPslkTvS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skKnVTGukAjA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "review = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IST 707/us_hotel_review.csv\")"
      ],
      "metadata": {
        "id": "gviZokKJkikr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) EDA**"
      ],
      "metadata": {
        "id": "-Zzrdj1vklhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Information of the Data Structure**"
      ],
      "metadata": {
        "id": "9uCPCZGrlltk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set, '`review`' has 35,437 reviews with the following three attributes.\n",
        "1. **`is_positive`**: whether the review is positive or negative (positive = '`y`', negative = '`n`')\n",
        "2. **`Reviewer_score`**: the review score (10 points scale)\n",
        "3. **`review`**: actual reviews, string values"
      ],
      "metadata": {
        "id": "n9sldWz0kprH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review.shape"
      ],
      "metadata": {
        "id": "4Eu6P3Q1knep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review.head()"
      ],
      "metadata": {
        "id": "gnIMPxAkWAys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Missing Values**"
      ],
      "metadata": {
        "id": "uZC9iB98lrjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values in all attributes."
      ],
      "metadata": {
        "id": "plDNre7Ulvfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review.isna().sum()"
      ],
      "metadata": {
        "id": "DTv3eDThltgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Value Transformation** <br>\n",
        "For further modeling, convert the character values in **`is_positive`** to numeric values.\n",
        "- positive ('y') = 1\n",
        "- negative ('n') = 0"
      ],
      "metadata": {
        "id": "gPWCLxL8l00w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = review.replace('y', 1)\n",
        "review = review.replace('n', 0)"
      ],
      "metadata": {
        "id": "KaP4BDUPmJ13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Text Preprocessing**"
      ],
      "metadata": {
        "id": "iaQM8AMYmSRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Upload Required Classifiers for Text Preprocessing**\n",
        "\n",
        "Before text preprocessing, upload the following necessary classifiers in this environment. \n",
        "- Sentence Tokenizer\n",
        "- Stopwords\n",
        "- RegexpTokenizer\n",
        "- WordNetLemmatizer\n",
        "- PorterStemmer"
      ],
      "metadata": {
        "id": "_0rkNQy3mcz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "NEGfcKlrn6u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "VQbn1MF-m_Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RegexpTokenizer\n",
        "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
        "regexp_tokenizer = RegexpTokenizer('[\\'a-zA-Z]+')"
      ],
      "metadata": {
        "id": "-6Cj4wFfnBES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WordNetLemmatizer and PorterStemmer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "porter_stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "grx1gfeonFi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Define a Function for Text Preprocessing** <br>\n",
        "For convenience, make a customized function to conduct text preprocessing that includes the above required tools."
      ],
      "metadata": {
        "id": "RAHv38BHnMsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "def text_preprocess(document, rebuild_document = True):\n",
        "  words = []\n",
        "\n",
        "  for sentence in sent_tokenize(document):\n",
        "    tokens = [wordnet_lemmatizer.lemmatize(t.lower()) for t in regexp_tokenizer.tokenize(sentence) if t.lower() not in stop_words]\n",
        "    words += tokens\n",
        "  if rebuild_document:\n",
        "    content = ' '.join(words).strip()\n",
        "    content = content.replace(r\"'\",\" \")\n",
        "    content = re.sub('s\\+', ' ', content)\n",
        "    content = content.strip()\n",
        "\n",
        "    return content\n",
        "  else:\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "id": "TMe9l84sne-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Implement Text Preprocessing**"
      ],
      "metadata": {
        "id": "ZcfRBqOnnhwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new lists of review texts, tokenized review texts, and sentiment labels to split the review text data into predictive and target variables. "
      ],
      "metadata": {
        "id": "CdSw1TNvn_ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_reviews = [] # review texts after text preprocessing\n",
        "X_token_reviews = [] # tokenized review texts after text preprocessing\n",
        "Y_reviews = [] # sentiment labels"
      ],
      "metadata": {
        "id": "zKnrQcELnheo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a for loop to divide the data set and append values into the new lists."
      ],
      "metadata": {
        "id": "YIrtBnc5oOn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in review.iterrows():\n",
        "  sentiment_index = row.is_positive\n",
        "  review = row.review\n",
        "\n",
        "  X_reviews.append(text_preprocess(review))\n",
        "  X_token_reviews.append(text_preprocess(review, False))\n",
        "  Y_reviews.append(sentiment_index)"
      ],
      "metadata": {
        "id": "3QAZeTEInKNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the samples of new lists."
      ],
      "metadata": {
        "id": "OpFu0UX4pIrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_reviews: ', X_reviews[0])"
      ],
      "metadata": {
        "id": "zxKCLVtKpJ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_token_reviews: ', X_token_reviews[0])"
      ],
      "metadata": {
        "id": "RHF5vi8NpM3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Y_reviews: ', Y_reviews[0:10])"
      ],
      "metadata": {
        "id": "vkIdmW_upN2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Vectorization & Feature Selection**"
      ],
      "metadata": {
        "id": "wMyGvwwtpWC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two techniques that will be used in this step: Count Vectorizer and TD-IDF."
      ],
      "metadata": {
        "id": "mKXxHj4WpYGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is **Count Vectorization**?\n",
        "- It counts the frequency of each word in a document.\n",
        "- It shows a document as **a vector of word frequencies**. \n",
        "\n",
        "What is **TD-IDF**?\n",
        "- It takes into account both the frequency of a word in a document and the quality (states or facts) across all documents. \n",
        "- It represents **a document as a vector of weights** that represent the importance of each word in the document and in the corpus. "
      ],
      "metadata": {
        "id": "SSoAistYE8Ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4-1) Count Vectorization**"
      ],
      "metadata": {
        "id": "vJcuIuiDpekE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Import the Required Classifier**"
      ],
      "metadata": {
        "id": "5-vAGEumpjWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()"
      ],
      "metadata": {
        "id": "Gyat1Yaopg39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Transform `X_reviews` Using Count Vectorization Classifier**"
      ],
      "metadata": {
        "id": "5N8E5ajCpqWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_reviews_cv = count_vectorizer.fit_transform(X_reviews)"
      ],
      "metadata": {
        "id": "InkBxn1GpwWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Calculate the Gain Ratio for Selecting Features** <br>\n",
        "Compute the **gain ratio** of each feature from the data set after running count vectorization. <br>\n",
        "The **gain ratio** will be a standard of feature selection."
      ],
      "metadata": {
        "id": "T-smbRIJpxj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import numpy as np\n",
        "\n",
        "mi_cv = mutual_info_classif(X_reviews_cv, Y_reviews)\n",
        "feature_scores_cv = mi_cv / np.log2(X_reviews_cv.shape[1])"
      ],
      "metadata": {
        "id": "bhWKekCLqQXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Select Top 15 Features** <br>\n",
        "Select top 15 features based on the gain ratio scores."
      ],
      "metadata": {
        "id": "cu7mMlx-qTOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the name of features\n",
        "feature_names_cv = count_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "NeXBM5DBqSkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the top 15 features using gain ratios\n",
        "k = 15\n",
        "top_index_cv = np.argsort(feature_scores_cv)[-k:]\n",
        "top_names_cv = [feature_names_cv[i] for i in top_index_cv]\n",
        "top_scores_cv = [feature_scores_cv[i] for i in top_index_cv]"
      ],
      "metadata": {
        "id": "7zIWSp28q8UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The set of top 15 features from the reviews after count vectorization includes words that express sentiments as follows. \n",
        "- **Positive**: positive, great, excellent, helpful, confortable, friendly\n",
        "- **Negative**: negative, rude, horrible, never, bad, poor"
      ],
      "metadata": {
        "id": "kuOMQhSGrK-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the selected features and their gain ratio scores\n",
        "pd.DataFrame({'Features': top_names_cv, 'Scores' : top_scores_cv}).sort_values('Scores', ascending = False).reset_index().drop(labels='index',axis=1)"
      ],
      "metadata": {
        "id": "wpsLRL5mrCjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4-2) TD-IDF**\n"
      ],
      "metadata": {
        "id": "tgVQoKHsrwRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Import the Required Classifier**"
      ],
      "metadata": {
        "id": "QxWRMouxr0OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tdidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "EjNEOcJ_r1Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Transform `X_reviews` Using TD-IDF Classifier**"
      ],
      "metadata": {
        "id": "GwS0EDiGr2hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_reviews_tdidf = tdidf.fit_transform(X_reviews)"
      ],
      "metadata": {
        "id": "dXzijhS_r5Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Calculate the Gain Ratio for Selecting Features** <br>\n",
        "Compute the gain ratio of each feature from the data set after running TD-IDF Vectorization. <br>\n",
        "The gain ratio will be a standard of feature selection."
      ],
      "metadata": {
        "id": "ZVIKfPFAr7Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import numpy as np\n",
        "\n",
        "mi_tdidf = mutual_info_classif(X_reviews_tdidf, Y_reviews)\n",
        "feature_scores_tdidf = mi_tdidf / np.log2(X_reviews_tdidf.shape[1])"
      ],
      "metadata": {
        "id": "1aOTWgM7r7_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Select Top 15 Features** <br>\n",
        "Select top 15 features based on the gain ratio scores."
      ],
      "metadata": {
        "id": "FI8Uo-DnuLkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the name of features\n",
        "feature_names_tdidf = tdidf.get_feature_names_out()"
      ],
      "metadata": {
        "id": "cO6Bgx4PuJKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the top 15 features using gain ratio scores\n",
        "k = 15\n",
        "top_index_tdidf = np.argsort(feature_scores_tdidf)[-k:]\n",
        "top_names_tdidf = [feature_names_tdidf[i] for i in top_index_tdidf]\n",
        "top_scores_tdidf = [feature_scores_tdidf[i] for i in top_index_tdidf]"
      ],
      "metadata": {
        "id": "jq547J8puSdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The set of top 15 features from the reviews after TD-IDF includes more words that indicates categories for reviewing, including room, staff, location, bed, and bathroom, than the reviews after count vectorization. In other words, the TD-IDF doesn't have words with a high gain ratio that related to sentiments.\n",
        "\n",
        "- **Category**: room, staff, location, bed, bathroom\n",
        "- **Sentiment**: positive, good, like (It can have more than two meanings)"
      ],
      "metadata": {
        "id": "s9yu2IHYucSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the selected top 15 features\n",
        "pd.DataFrame({'Features': top_names_tdidf, 'Scores' : top_scores_tdidf}).sort_values('Scores', ascending = False).reset_index().drop(labels='index',axis=1)"
      ],
      "metadata": {
        "id": "1fJkjUGquWl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Modeling**"
      ],
      "metadata": {
        "id": "mLz04-wRvcfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build sentiment classification and lie detection models using the following machine learning techniques. \n",
        "- **Sentiment Classification**: MultinomialNB (Naive Bayes), SVM(Support Vector Machine)\n",
        "- **Lie Detection**: Decision Tree, Random Forest"
      ],
      "metadata": {
        "id": "K1ODB8F3wd23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5-1) Create the new review and sentiment label sets after vectorization and feature selection** <Br>\n",
        "Create the new review and sentiment label sets based on the selected top 15 features from Count Vectorization and TD-IDF."
      ],
      "metadata": {
        "id": "4Pi8FIhBzByC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_reviews_cv_top = X_reviews_cv[:, top_index_cv]\n",
        "X_reviews_tdidf_top = X_reviews_tdidf[:, top_index_tdidf]"
      ],
      "metadata": {
        "id": "rFPfzkq9zWVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5-2) Split into train and test sets** <br>\n",
        "For modeling, divide the review and sentiment label data into train and test sets."
      ],
      "metadata": {
        "id": "o8vikTcIw5Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorized reviews\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_reviews_cv_top, Y_reviews, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MOKLXafBxCfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TD-IDF reviews\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_tdidf, X_test_tdidf, y_train_tdidf, y_test_tdidf = train_test_split(X_reviews_tdidf_top, Y_reviews, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HLnCL5Q7z1UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5-3) Sentiment Classification** <br>\n",
        "\n",
        "`MultinomialNB (Naive Bayes)` and `SVM(Support Vector Machine)` models are used for building the sentiment classification algorithm."
      ],
      "metadata": {
        "id": "EAY7s-i3vgkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MultinomialNB (Naive Bayes)**"
      ],
      "metadata": {
        "id": "WBhnE-54wZkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Import Required Classifier**"
      ],
      "metadata": {
        "id": "S0jgVkUUxQwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "ld_cv_nb = MultinomialNB()\n",
        "ld_tdidf_nb = MultinomialNB()"
      ],
      "metadata": {
        "id": "nL8WIbgLxOEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Train the model with default parameters** <br>\n",
        "To get a baseline for hyperparameter tuning, train the model with its default parameter setting."
      ],
      "metadata": {
        "id": "4_aSAMrtxVoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorization model\n",
        "ld_cv_nb.fit(X_train_cv, y_train_cv)\n",
        "y_pred_cv_nb = ld_cv_nb.predict(X_test_cv)"
      ],
      "metadata": {
        "id": "fpgpaoNN0SAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TD-IDF reviews\n",
        "ld_tdidf_nb.fit(X_train_tdidf, y_train_tdidf)\n",
        "y_pred_tdidf_nb = ld_tdidf_nb.predict(X_test_tdidf)"
      ],
      "metadata": {
        "id": "IGlGrfaXxex4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Check the Default Parameter**"
      ],
      "metadata": {
        "id": "lwNMuMzu0LJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_cv_nb.get_params()))"
      ],
      "metadata": {
        "id": "2B8jgx860sU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_tdidf_nb.get_params()))"
      ],
      "metadata": {
        "id": "HGEHJOQ305dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Evaluate the Models**"
      ],
      "metadata": {
        "id": "cVawF0uZ0U4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## count vectorization\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred_cv_nb)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_cv, y_pred_cv_nb))\n",
        "print('Precision:',precision_score(y_test_cv, y_pred_cv_nb))\n",
        "print('Recall:',recall_score(y_test_cv, y_pred_cv_nb))\n",
        "print('F1:',f1_score(y_test_cv, y_pred_cv_nb))"
      ],
      "metadata": {
        "id": "Ojjt1SVW0GgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cf_matrix_cv_nb = confusion_matrix(y_test_cv, y_pred_cv_nb)\n",
        "sns.heatmap(cf_matrix_cv_nb/np.sum(cf_matrix_cv_nb), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "sDTHZ1mw71-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TD-IDF\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_tdidf, y_pred_tdidf_nb)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_tdidf, y_pred_tdidf_nb))\n",
        "print('Precision:',precision_score(y_test_tdidf, y_pred_tdidf_nb))\n",
        "print('Recall:',recall_score(y_test_tdidf, y_pred_tdidf_nb))\n",
        "print('F1:',f1_score(y_test_tdidf, y_pred_tdidf_nb))"
      ],
      "metadata": {
        "id": "EhKaH0s20XKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_tdidf_nb = confusion_matrix(y_test_tdidf, y_pred_tdidf_nb)\n",
        "sns.heatmap(cf_matrix_tdidf_nb/np.sum(cf_matrix_tdidf_nb), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "FuD2xGBM8aV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Hyperparameter Tuning** <br>\n",
        "Conduct hyperparameter tuning to find the parameters that make better performances. <br>\n",
        "<br>\n",
        "In this case, find the best parameter that make a good **roc_auc** score. <br>\n",
        "Only **`C`** parameter will be controlled in this step."
      ],
      "metadata": {
        "id": "NSyjyb021PfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = np.linspace(0.1, 1.0, 10, endpoint = True)\n",
        "parameters = {'alpha': alpha}"
      ],
      "metadata": {
        "id": "5LVqLqhT1kB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the parameter grid to the classifier. <br>\n",
        "In this hyperparameter tuning, we will focus on improving AUC scores."
      ],
      "metadata": {
        "id": "0EBPvoSe1Zhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "ld_cv_nb_hyper = GridSearchCV(MultinomialNB(), param_grid = parameters, cv=3, return_train_score=True, scoring= 'roc_auc')"
      ],
      "metadata": {
        "id": "ao5Xmkef23Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a model again and print the best parameters"
      ],
      "metadata": {
        "id": "6HYg9jtd3jI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorization reviews\n",
        "ld_cv_nb_hyper.fit(X_train_cv, y_train_cv)\n",
        "print('Best model: %s' % str(ld_cv_nb_hyper.best_params_))"
      ],
      "metadata": {
        "id": "8H_Q-3Rr3mJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a model with the best parameters (`alpha` = 0.8) and evaluate measure scores."
      ],
      "metadata": {
        "id": "tWF6Spqo4Y2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "ld_cv_nb_best = ld_cv_nb_hyper.best_estimator_\n",
        "ld_cv_nb_best.fit(X_train_cv, y_train_cv)\n",
        "y_pred_cv_nb_best = ld_cv_nb_best.predict(X_test_cv)"
      ],
      "metadata": {
        "id": "9DwUn5dG4dKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, the **roc_auc** score after hyperparameter tuning decreased by about 0.0001."
      ],
      "metadata": {
        "id": "MT4xN1he9yJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred_cv_nb_best)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_cv, y_pred_cv_nb_best))\n",
        "print('Precision:',precision_score(y_test_cv, y_pred_cv_nb_best))\n",
        "print('Recall:',recall_score(y_test_cv, y_pred_cv_nb_best))\n",
        "print('F1:',f1_score(y_test_cv, y_pred_cv_nb_best))"
      ],
      "metadata": {
        "id": "hCQIM-6g4mFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, the multinomialNB model with the hyperparameters can't divide positive and negative values exactly."
      ],
      "metadata": {
        "id": "46i3_Kk999Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_cv_nb_best = confusion_matrix(y_test_cv, y_pred_cv_nb_best)\n",
        "sns.heatmap(cf_matrix_cv_nb_best/np.sum(cf_matrix_cv_nb_best), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "125VcFwh9MJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conduct hyperparameter tuning with the tdidf data sets."
      ],
      "metadata": {
        "id": "0zoBxQgoP1tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "ld_tdidf_nb_hyper = GridSearchCV(MultinomialNB(), param_grid = parameters, cv=3, return_train_score=True, scoring= 'roc_auc')"
      ],
      "metadata": {
        "id": "IMWmDe75P1Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tdidf review\n",
        "ld_tdidf_nb_hyper.fit(X_train_tdidf, y_train_tdidf)\n",
        "print('Best model: %s' % str(ld_tdidf_nb_hyper.best_params_))"
      ],
      "metadata": {
        "id": "WLqSVVSuP7WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "ld_tdidf_nb_best = ld_tdidf_nb_hyper.best_estimator_\n",
        "ld_tdidf_nb_best.fit(X_train_tdidf, y_train_tdidf)\n",
        "y_pred_tdidf_nb_best = ld_tdidf_nb_best.predict(X_test_tdidf)"
      ],
      "metadata": {
        "id": "pjHyTYqSQACa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_tdidf, y_pred_tdidf_nb_best)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_tdidf, y_pred_tdidf_nb_best))\n",
        "print('Precision:',precision_score(y_test_tdidf, y_pred_tdidf_nb_best))\n",
        "print('Recall:',recall_score(y_test_tdidf, y_pred_tdidf_nb_best))\n",
        "print('F1:',f1_score(y_test_tdidf, y_pred_tdidf_nb_best))"
      ],
      "metadata": {
        "id": "yk9EuZ2NQHOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_tdidf_nb_best = confusion_matrix(y_test_tdidf, y_pred_tdidf_nb_best)\n",
        "sns.heatmap(cf_matrix_tdidf_nb_best/np.sum(cf_matrix_tdidf_nb_best), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "J2YAeuN0QLzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**SVM (Support Vector Machine)**"
      ],
      "metadata": {
        "id": "_zTTjb8I5R4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Import Required Classifier**"
      ],
      "metadata": {
        "id": "KLH6XMxP5R4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "ld_cv_svm = SVC()\n",
        "ld_tdidf_svm = SVC()"
      ],
      "metadata": {
        "id": "MPIzpjSP5R4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Train the model with default parameters** <br>\n",
        "To get a baseline for hyperparameter tuning, train the model with its default parameter setting."
      ],
      "metadata": {
        "id": "2wmGAQK_5R4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorization model\n",
        "ld_cv_svm.fit(X_train_cv, y_train_cv)\n",
        "y_pred_cv_svm = ld_cv_svm.predict(X_test_cv)"
      ],
      "metadata": {
        "id": "vMcC1rZ55R4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TD-IDF reviews\n",
        "ld_tdidf_svm.fit(X_train_tdidf, y_train_tdidf)\n",
        "y_pred_tdidf_svm = ld_tdidf_svm.predict(X_test_tdidf)"
      ],
      "metadata": {
        "id": "N7hAAfZe5R4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Check the Default Parameter**"
      ],
      "metadata": {
        "id": "USg9zw055R4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_cv_svm.get_params()))"
      ],
      "metadata": {
        "id": "OEgy2aZn5R4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_tdidf_svm.get_params()))"
      ],
      "metadata": {
        "id": "8N6LhhYv5R4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Evaluate the Models**"
      ],
      "metadata": {
        "id": "-bBWHGJr5R4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## count vectorization\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred_cv_svm)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_cv, y_pred_cv_svm))\n",
        "print('Precision:',precision_score(y_test_cv, y_pred_cv_svm))\n",
        "print('Recall:',recall_score(y_test_cv, y_pred_cv_svm))\n",
        "print('F1:',f1_score(y_test_cv, y_pred_cv_svm))"
      ],
      "metadata": {
        "id": "OMKdaigY5R4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_cv_svm = confusion_matrix(y_test_cv, y_pred_cv_svm)\n",
        "sns.heatmap(cf_matrix_cv_svm/np.sum(cf_matrix_cv_svm), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "cm5W1CyA-JGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TD-IDF\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_tdidf, y_pred_tdidf_nb)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_tdidf, y_pred_tdidf_svm))\n",
        "print('Precision:',precision_score(y_test_tdidf, y_pred_tdidf_svm))\n",
        "print('Recall:',recall_score(y_test_tdidf, y_pred_tdidf_svm))\n",
        "print('F1:',f1_score(y_test_tdidf, y_pred_tdidf_svm))"
      ],
      "metadata": {
        "id": "5DkUPu9K5R4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_tdidf_svm = confusion_matrix(y_test_tdidf, y_pred_tdidf_svm)\n",
        "sns.heatmap(cf_matrix_tdidf_svm/np.sum(cf_matrix_tdidf_svm), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "C50wKkyg-Oui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Hyperparameter Tuning** <br>\n",
        "Conduct hyperparameter tuning to find the parameters that make better performances. <br>\n",
        "<br>\n",
        "In this case, find the best parameter that make a good **roc_auc** score. <br>\n",
        "Use `kernel`, `c`, and `gamma` as the parameter for hyperparameter tuning."
      ],
      "metadata": {
        "id": "PZWtFYRXO0v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = ['linear', 'rbf']\n",
        "C = [1,10,20,50,100]\n",
        "gamma = [0.1, 0.01, 0.001]\n",
        "parameters = {'kernel': kernel, 'C': C, 'gamma': gamma}"
      ],
      "metadata": {
        "id": "3OgBrifSO0v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the parameter grid to the classifier. <br>\n",
        "In this hyperparameter tuning, we will focus on improving AUC scores."
      ],
      "metadata": {
        "id": "2GStqZurO0v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "ld_cv_svm_hyper = GridSearchCV(SVC(), param_grid = parameters, cv=3, return_train_score=True, scoring= 'roc_auc')"
      ],
      "metadata": {
        "id": "OFVClzIwO0v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a model again and print the best parameters"
      ],
      "metadata": {
        "id": "BHbPiWPCO0v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorization reviews\n",
        "ld_cv_svm_hyper.fit(X_train_cv, y_train_cv)\n",
        "print('Best model: %s' % str(ld_cv_svm_hyper.best_params_))"
      ],
      "metadata": {
        "id": "h67toxi-O0v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a model with the best parameters (`alpha` = 0.8) and evaluate measure scores."
      ],
      "metadata": {
        "id": "Zwaw4cXDO0v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "ld_cv_svm_best = ld_cv_svm_hyper.best_estimator_\n",
        "ld_cv_svm_best.fit(X_train_cv, y_train_cv)\n",
        "y_pred_cv_svm_best = ld_cv_svm_best.predict(X_test_cv)"
      ],
      "metadata": {
        "id": "Ibn--aKfO0v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unfortunately, the **roc_auc** score after hyperparameter tuning decreased by about 0.0001."
      ],
      "metadata": {
        "id": "CQviJ55-O0v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred_cv_svm_best)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_cv, y_pred_cv_svm_best))\n",
        "print('Precision:',precision_score(y_test_cv, y_pred_cv_svm_best))\n",
        "print('Recall:',recall_score(y_test_cv, y_pred_cv_svm_best))\n",
        "print('F1:',f1_score(y_test_cv, y_pred_cv_svm_best))"
      ],
      "metadata": {
        "id": "juF7MNkBO0v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, the SVM model with the hyperparameters can't divide positive and negative values correctly."
      ],
      "metadata": {
        "id": "9fgM8etRO0v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_cv_svm_best = confusion_matrix(y_test_cv, y_pred_cv_svm_best)\n",
        "sns.heatmap(cf_matrix_cv_svm_best/np.sum(cf_matrix_cv_svm_best), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "DwOC5rV8O0v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5-4) Lie Detection** <br>\n",
        "\n",
        "`Decision Tree` and `Random Forest` models are used for building the lie detection algorithm."
      ],
      "metadata": {
        "id": "yXypQehK51CO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "Ej2OMfNs51CO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Import Required Classifier**"
      ],
      "metadata": {
        "id": "9V8VpRRd51CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ld_cv_dt = DecisionTreeClassifier()\n",
        "ld_tdidf_dt = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "YvQXEXka51CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Train the model with default parameters** <br>\n",
        "To get a baseline for hyperparameter tuning, train the model with its default parameter setting."
      ],
      "metadata": {
        "id": "-vgg8Vc-51CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorization model\n",
        "ld_cv_dt.fit(X_train_cv, y_train_cv)\n",
        "y_pred_cv_dt = ld_cv_dt.predict(X_test_cv)"
      ],
      "metadata": {
        "id": "B_RAmQww51CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TD-IDF reviews\n",
        "ld_tdidf_dt.fit(X_train_tdidf, y_train_tdidf)\n",
        "y_pred_tdidf_dt = ld_tdidf_dt.predict(X_test_tdidf)"
      ],
      "metadata": {
        "id": "hbe1r0a851CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Check the Default Parameter**"
      ],
      "metadata": {
        "id": "nnbWQBmu51CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_cv_dt.get_params()))"
      ],
      "metadata": {
        "id": "8Mv7CPe751CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_tdidf_dt.get_params()))"
      ],
      "metadata": {
        "id": "9G7PU55n51CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Evaluate the Models**"
      ],
      "metadata": {
        "id": "o0E6qcHQ51CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## count vectorization\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred_cv_dt)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_cv, y_pred_cv_dt))\n",
        "print('Precision:',precision_score(y_test_cv, y_pred_cv_dt))\n",
        "print('Recall:',recall_score(y_test_cv, y_pred_cv_dt))\n",
        "print('F1:',f1_score(y_test_cv, y_pred_cv_dt))"
      ],
      "metadata": {
        "id": "MB23Arxu51CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_cv_df = confusion_matrix(y_test_cv, y_pred_cv_dt)\n",
        "sns.heatmap(cf_matrix_cv_df/np.sum(cf_matrix_cv_df), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "bNTk4IyN-cbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TD-IDF\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_tdidf, y_pred_tdidf_nb)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_tdidf, y_pred_tdidf_dt))\n",
        "print('Precision:',precision_score(y_test_tdidf, y_pred_tdidf_dt))\n",
        "print('Recall:',recall_score(y_test_tdidf, y_pred_tdidf_dt))\n",
        "print('F1:',f1_score(y_test_tdidf, y_pred_tdidf_dt))"
      ],
      "metadata": {
        "id": "DhEADxfz51CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_tdidf_df = confusion_matrix(y_test_tdidf, y_pred_tdidf_dt)\n",
        "sns.heatmap(cf_matrix_tdidf_df/np.sum(cf_matrix_tdidf_df), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "nDlnGQkF-nJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Hyperparameter Tuning** <br>\n",
        "Conduct hyperparameter tuning to find the parameters that make better performances. <br>\n",
        "<br>\n",
        "Only **`C`** parameter will be controlled in this step."
      ],
      "metadata": {
        "id": "f6BlwshR51CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = np.linspace(0.1, 1.0, 10, endpoint = True)\n",
        "parameters = {'alpha': alpha}"
      ],
      "metadata": {
        "id": "g9VJyVJY51CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the parameter grid to the classifier"
      ],
      "metadata": {
        "id": "TL0xhoCM51CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "ld_cv_nb_hyper = GridSearchCV(MultinomialNB(), param_grid = parameters, cv=3, return_train_score=True, scoring= 'roc_auc')"
      ],
      "metadata": {
        "id": "Sitk8D4j51CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a model again and print the best parameters"
      ],
      "metadata": {
        "id": "0AbzsaHW51CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorization reviews\n",
        "ld_cv_nb_hyper.fit(X_train_cv, y_train_cv)\n",
        "print('Best model: %s' % str(ld_cv_nb_hyper.best_params_))"
      ],
      "metadata": {
        "id": "qzPyXQQf51CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a model with the best parameters and evaluate auc and accuracy scores."
      ],
      "metadata": {
        "id": "QTZ-H2-o51CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "ld_cv_nb_best = ld_cv_nb_hyper.best_estimator_\n",
        "ld_cv_nb_best.fit(X_train_cv, y_train_cv)\n",
        "y_pred_cv_nb_best = ld_cv_nb_best.predict(X_test_cv)"
      ],
      "metadata": {
        "id": "sVnF4kON51CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred_cv_nb_best)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_cv, y_pred_cv_nb_best))\n",
        "print('Precision:',precision_score(y_test_cv, y_pred_cv_nb_best))\n",
        "print('Recall:',recall_score(y_test_cv, y_pred_cv_nb_best))\n",
        "print('F1:',f1_score(y_test_cv, y_pred_cv_nb_best))"
      ],
      "metadata": {
        "id": "-csjx16Z51CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "MubdISy_51CR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Import Required Classifier**"
      ],
      "metadata": {
        "id": "RltqW2Fs51CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "ld_cv_rf = RandomForestClassifier()\n",
        "ld_tdidf_rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "-ePm0Jst51CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Train the model with default parameters** <br>\n",
        "To get a baseline for hyperparameter tuning, train the model with its default parameter setting."
      ],
      "metadata": {
        "id": "1mj-TDlF51CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorization model\n",
        "ld_cv_rf.fit(X_train_cv, y_train_cv)\n",
        "y_pred_cv_rf = ld_cv_rf.predict(X_test_cv)"
      ],
      "metadata": {
        "id": "KilCd07m51CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TD-IDF reviews\n",
        "ld_tdidf_rf.fit(X_train_tdidf, y_train_tdidf)\n",
        "y_pred_tdidf_rf = ld_tdidf_rf.predict(X_test_tdidf)"
      ],
      "metadata": {
        "id": "-Br79dv351CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Check the Default Parameter**"
      ],
      "metadata": {
        "id": "RdmSlL1v51CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_cv_rf.get_params()))"
      ],
      "metadata": {
        "id": "szjyAtKy51CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(ld_tdidf_rf.get_params()))"
      ],
      "metadata": {
        "id": "3373OWmr51CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Evaluate the Models**"
      ],
      "metadata": {
        "id": "i9YXsBHU51CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## count vectorization\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_cv, y_pred_cv_rf)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_cv, y_pred_cv_rf))\n",
        "print('Precision:',precision_score(y_test_cv, y_pred_cv_rf))\n",
        "print('Recall:',recall_score(y_test_cv, y_pred_cv_rf))\n",
        "print('F1:',f1_score(y_test_cv, y_pred_cv_rf))"
      ],
      "metadata": {
        "id": "HNqxisg651CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_cv_rf = confusion_matrix(y_test_cv, y_pred_cv_rf)\n",
        "sns.heatmap(cf_matrix_cv_rf/np.sum(cf_matrix_cv_rf), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "xuX3vt2Q-yBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TD-IDF\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_tdidf, y_pred_tdidf_rf)\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print('ROC_AUC:',roc_auc)\n",
        "print('Accuracy:',accuracy_score(y_test_tdidf, y_pred_tdidf_rf))\n",
        "print('Precision:',precision_score(y_test_tdidf, y_pred_tdidf_rf))\n",
        "print('Recall:',recall_score(y_test_tdidf, y_pred_tdidf_rf))\n",
        "print('F1:',f1_score(y_test_tdidf, y_pred_tdidf_rf))"
      ],
      "metadata": {
        "id": "I_G_xJci51CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix_tdidf_rf = confusion_matrix(y_test_tdidf, y_pred_tdidf_rf)\n",
        "sns.heatmap(cf_matrix_tdidf_rf/np.sum(cf_matrix_tdidf_rf), annot=True, fmt='.2%')"
      ],
      "metadata": {
        "id": "x7cg9LEi-3YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Evaluation**\n",
        "Check read_me in my github [Link]()"
      ],
      "metadata": {
        "id": "xfItWVzzKs6B"
      }
    }
  ]
}